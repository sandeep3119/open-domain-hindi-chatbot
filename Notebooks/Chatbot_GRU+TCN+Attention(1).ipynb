{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReQ_0EZI2UDR"
      },
      "source": [
        "#Chatbot RNN + TCN +Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBs8lwEwQEZd",
        "outputId": "00346a7b-9a30-4510-b2e4-494f342cbdd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sijKswUUAHf",
        "outputId": "c608bffe-d3dd-4b4a-f070-403715ada704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 11 10:57:46 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb47J37kZS-4"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ss9JD47u1VWg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "import itertools\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from collections import Counter\n",
        "# from torch.nn.modules.conv import TemporalConvNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBld9HqAICil",
        "outputId": "3c9bd18e-2635-4650-a2ab-93f630764f25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy6LpS842_70"
      },
      "outputs": [],
      "source": [
        "CUDA= torch.cuda.is_available()\n",
        "device=torch.device(\"cuda\" if CUDA else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47gTHH7zXS0L"
      },
      "source": [
        "## Load Hindi Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHzNns3TXWxK"
      },
      "outputs": [],
      "source": [
        "base='/content/drive/MyDrive/Chatbot_research'\n",
        "os.chdir(base)\n",
        "##Dialog File Train\n",
        "corpus_name='daily_dialog_corpus_hindi'\n",
        "train_file=os.path.join(base,'formatted_hindi_train_merged.txt')\n",
        "test_file=os.path.join(base,'formatted_hindi_test.txt')\n",
        "val_file=os.path.join(base,'formatted_hindi_val.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9B68DUezCfo",
        "outputId": "c8c854be-f1ca-4653-b9bd-7777858825e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Sample Train Lines\n",
            "यह फर्जी है। मुझे काम पर कोई तनाव महसूस नहीं होता है, और मेरा प्रेम जीवन व्यावहारिक रूप से अस्तित्वहीन है। यह राशि की सारी बातें बकवास हैं।\tनहीं, ऐसा नहीं है, आपका ज्योतिष संकेत आपको आपके व्यक्तित्व के बारे में बहुत कुछ बता सकता है। देखिए? इसमें कहा गया है कि मेष ऊर्जावान होता है और उसे सामाजिक जीवन पसंद होता है।\n",
            "\n",
            "नहीं, ऐसा नहीं है, आपका ज्योतिष संकेत आपको आपके व्यक्तित्व के बारे में बहुत कुछ बता सकता है। देखिए? इसमें कहा गया है कि मेष ऊर्जावान होता है और उसे सामाजिक जीवन पसंद होता है।\tखैर, आप निश्चित रूप से उन मानदंडों से मेल खाते हैं, लेकिन वे इतने व्यापक हैं कि वे किसी पर भी लागू हो सकते हैं। यह मेरे बारे में क्या कहता है?\n",
            "\n",
            "खैर, आप निश्चित रूप से उन मानदंडों से मेल खाते हैं, लेकिन वे इतने व्यापक हैं कि वे किसी पर भी लागू हो सकते हैं। यह मेरे बारे में क्या कहता है?\tएक मकर राशि गंभीर और व्यावहारिक होती है। उसे पारंपरिक तरीकों से काम करना पसंद है। यह बिल्कुल आपकी तरह लगता है।\n",
            "\n",
            "फ्रैंक की शादी हो रही है, क्या आप इस पर विश्वास करते हैं?\tक्या वह वास्तव में है?\n",
            "\n",
            "क्या वह वास्तव में है?\tवह उस लड़की से बहुत प्यार करता है।\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('\\n Sample Train Lines')\n",
        "with open(train_file,'r') as f:\n",
        "  lines=f.readlines()\n",
        "\n",
        "for line in lines[35:40]:\n",
        "  print(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAMCZYAvzI0_",
        "outputId": "6485add2-816f-4302-ad09-37e7b8d9ead4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Sample test Lines\n",
            "6740\n",
            "क्या आप एक नेता हैं या अनुयायी?\tमैं लोगों का नेतृत्व करने की कोशिश नहीं करता। मैं इसके बजाय सभी के साथ सहयोग करूंगा और मिलकर काम करके काम पूरा करूंगा।\n",
            "\n",
            "मैं लोगों का नेतृत्व करने की कोशिश नहीं करता। मैं इसके बजाय सभी के साथ सहयोग करूंगा और मिलकर काम करके काम पूरा करूंगा।\tक्या आप सोचते हैं कि आप अपने आपको अंग्रेजी में आसानी से समझ सकते हैं?\n",
            "\n",
            "क्या आप सोचते हैं कि आप अपने आपको अंग्रेजी में आसानी से समझ सकते हैं?\tहां, ज्यादातर परिस्थितियों में।\n",
            "\n",
            "हां, ज्यादातर परिस्थितियों में।\tक्या आप यात्रा के लिए उपलब्ध हैं?\n",
            "\n",
            "क्या आप यात्रा के लिए उपलब्ध हैं?\tहां, मुझे यात्रा करना पसंद है। मैं युवा और अविवाहित हूं। मुझे अक्सर यात्रा करने में कोई समस्या नहीं है।\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('\\n Sample test Lines')\n",
        "with open(test_file,'r') as f:\n",
        "  lines=f.readlines()\n",
        "print(len(lines))\n",
        "for line in lines[35:40]:\n",
        "  print(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suCcZ9PtF98Z"
      },
      "source": [
        "## Load And Trim Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5w6JPNQGA-R"
      },
      "outputs": [],
      "source": [
        "PAD_tok=0\n",
        "SOS_tok=1\n",
        "EOS_tok=2\n",
        "OOV_tok=3\n",
        "\n",
        "class Vocabulary:\n",
        "  def __init__(self,name):\n",
        "    self.name=name\n",
        "    self.word2idx={}\n",
        "    self.word2count={}\n",
        "    self.idx2word={PAD_tok:'PAD',SOS_tok:'SOS',EOS_tok:'EOS',OOV_tok:'OOV'}\n",
        "    self.num_words=4\n",
        "    self.word2idx['OOV']=3\n",
        "  \n",
        "  def addLine(self,line):\n",
        "    for word in line.split(' '):\n",
        "      self.addWord(word)\n",
        "  def addWord(self,word):\n",
        "    if word not in self.word2idx:\n",
        "      self.word2idx[word]=self.num_words\n",
        "      self.word2count[word]=1\n",
        "      self.idx2word[self.num_words]=word\n",
        "      self.num_words+=1\n",
        "    else:\n",
        "      self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17HdNdt5KXfV"
      },
      "outputs": [],
      "source": [
        "def normalizeString(text):\n",
        "  # s = unicodeToASCII(s.lower().strip())\n",
        "   text = text.lower()\n",
        "   text = re.sub('((www.[^s]+)|(https?://[^s]+))','',text)\n",
        "   text = re.sub('@[^s]+','',text)\n",
        "   text = re.sub('[s]+', ' ', text)\n",
        "   text = re.sub(r'#([^s]+)', r'1', text)\n",
        "   text = re.sub('[.!:?-]', '', text)\n",
        "   text = re.sub('[a-zA-Z0-9]','',text)\n",
        "   text = re.sub(' +', ' ',text)\n",
        "   text = text.strip('\"\"')\n",
        "   return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy06y3I9ONy4",
        "outputId": "f3b3be4d-fb06-42ff-c833-2fadc76559f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading File please wait...\n",
            "Done Reading.....\n"
          ]
        }
      ],
      "source": [
        "print('Reading File please wait...')\n",
        "lines=open(train_file,).read().strip().split('\\n')\n",
        "pairs_data_train=[[normalizeString(s) for s in pair.split('\\t')] for pair in lines]\n",
        "print('Done Reading.....')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeWlRG549YD1",
        "outputId": "12080539-f9b4-44c2-9c57-5d983b19f8cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading File please wait...\n",
            "Done Reading.....\n"
          ]
        }
      ],
      "source": [
        "print('Reading File please wait...')\n",
        "lines=open(val_file,).read().strip().split('\\n')\n",
        "pairs_data_val=[[normalizeString(s) for s in pair.split('\\t')] for pair in lines]\n",
        "print('Done Reading.....')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsWDa_WLSv27",
        "outputId": "eea0095f-e348-45d2-91ec-3a1eabc0edb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 76053 pairs in the  train dataset\n",
            "After filtering, there are 43534 pair\n",
            "There are 7069 pairs in the validation dataset\n",
            "After filtering, there are 4076 pair\n"
          ]
        }
      ],
      "source": [
        "MAX_LENGTH=16\n",
        "# Load/Assemble voc and pairs\n",
        "save_dir = os.path.join(\"data\", \"save\")\n",
        "def filterPair(p):\n",
        "  return len(p[0].split())<MAX_LENGTH and len(p[1].split())<MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "  return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "pairs_train=pairs_data_train\n",
        "pairs_train=[pair for pair in pairs_train if len(pair)>1]\n",
        "print(\"There are {} pairs in the  train dataset\".format(len(pairs_train)))\n",
        "pairs_train=filterPairs(pairs_train)\n",
        "print('After filtering, there are {} pair'.format(len(pairs_train)))\n",
        "\n",
        "\n",
        "pairs_val=pairs_data_val\n",
        "pairs_val=[pair for pair in pairs_val if len(pair)>1]\n",
        "print(\"There are {} pairs in the validation dataset\".format(len(pairs_val)))\n",
        "pairs_val=filterPairs(pairs_val)\n",
        "print('After filtering, there are {} pair'.format(len(pairs_val)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlNqfkCvVFhe"
      },
      "source": [
        "##Creating Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-efxPCITuHg",
        "outputId": "ac932d0b-d1cb-44f6-c59d-5c892d163b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Vocabulary....\n",
            "counted words: 13906\n"
          ]
        }
      ],
      "source": [
        "print('Creating Vocabulary....')\n",
        "vocab=Vocabulary(corpus_name)\n",
        "\n",
        "for pair in pairs_train:\n",
        "  vocab.addLine(pair[0])\n",
        "  vocab.addLine(pair[1])\n",
        "print(\"counted words:\",vocab.num_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pretrained Embeddings"
      ],
      "metadata": {
        "id": "JllwNOY59duH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL9zREwnT7SJ",
        "outputId": "260424d7-a31b-4953-97c1-9cbf8258e958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3930, done.\u001b[K\n",
            "remote: Counting objects: 100% (958/958), done.\u001b[K\n",
            "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
            "remote: Total 3930 (delta 867), reused 817 (delta 817), pack-reused 2972\u001b[K\n",
            "Receiving objects: 100% (3930/3930), 8.24 MiB | 17.26 MiB/s, done.\n",
            "Resolving deltas: 100% (2505/2505), done.\n",
            "Updating files: 100% (526/526), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fastText"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv18DQNeT_xC",
        "outputId": "c60ed4b2-5b4a-4d49-a6c2-01920ffaa653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Chatbot_research/fastText\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HePYgz32UFAg",
        "outputId": "14655f27-a589-42a5-ad04-3b8f4f1d18d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/drive/MyDrive/Chatbot_research/fastText\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from fasttext==0.9.2) (67.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from fasttext==0.9.2) (1.22.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp39-cp39-linux_x86_64.whl size=4381862 sha256=f9b3049822451a467ff6721ba94446c9b391f50906967f23ef55347c60d461e0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iv7zym6m/wheels/73/fc/58/7576e77ca4efea93f598beb2abdd885074dacc456b5f3e318d\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oko6J16_UFrf",
        "outputId": "5258e33a-0824-4641-b194-d275c5863521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Chatbot_research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "ft_model = fasttext.load_model('cc.hi.300.bin')"
      ],
      "metadata": {
        "id": "qybe8nmu7d_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim=300\n",
        "embedding_matrix = np.zeros((vocab.num_words, emb_dim))\n",
        "\n",
        "for i, word in enumerate(vocab.word2idx):\n",
        "    if word in ft_model:\n",
        "        embedding_matrix[i] = ft_model[word]\n",
        "    else:\n",
        "        embedding_matrix[i] = np.random.randn(emb_dim)"
      ],
      "metadata": {
        "id": "cjKwWUQN7jva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
        "embedding_layer.requires_grad = False"
      ],
      "metadata": {
        "id": "W2mecqXM9auf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP4427-XZNZO"
      },
      "source": [
        "##Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiF0VCHbZPT-"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(vocab, sentence):\n",
        "    return [vocab.word2idx[word] if word in vocab.word2idx.keys() else vocab.word2idx['OOV'] for word in sentence.split(' ')] + [EOS_tok]\n",
        "\n",
        "\n",
        "def zeroPadding(l, fillvalue=PAD_tok):\n",
        "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
        "\n",
        "def binaryMatrix(l, value=PAD_tok):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == PAD_tok:\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m\n",
        "\n",
        "# Returns padded input sequence tensor and lengths\n",
        "def inputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, lengths\n",
        "\n",
        "# Returns padded target sequence tensor, padding mask, and max target length\n",
        "def outputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    mask = binaryMatrix(padList)\n",
        "    mask = torch.BoolTensor(mask)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, mask, max_target_len\n",
        "\n",
        "# Returns all items for a given batch of pairs\n",
        "def batch2TrainData(voc, pair_batch):\n",
        "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
        "    input_batch, output_batch = [], []\n",
        "    for pair in pair_batch:\n",
        "        input_batch.append(pair[0])\n",
        "        output_batch.append(pair[1])\n",
        "    inp, lengths = inputVar(input_batch, voc)\n",
        "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
        "    return inp, lengths, output, mask, max_target_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFXvA9I1vKH1"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ1iCatI004H"
      },
      "source": [
        "###1.Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYSMZd4WvQoP"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self,hidden_size,embedding,n_layers=1,dropout=0):\n",
        "    super(EncoderRNN,self).__init__()\n",
        "    self.n_layer=n_layers\n",
        "    self.hidden_size=hidden_size\n",
        "    self.embedding=embedding\n",
        "    self.gru=nn.GRU(hidden_size,hidden_size,n_layers,dropout=dropout,bidirectional=True)\n",
        "\n",
        "  def forward(self,input_seq,input_length,hidden=None):\n",
        "    embedded=self.embedding(input_seq)\n",
        "    packed=torch.nn.utils.rnn.pack_padded_sequence(embedded,input_length)\n",
        "    output,hidden=self.gru(packed,hidden)\n",
        "    output,_=torch.nn.utils.rnn.pad_packed_sequence(output)\n",
        "    output=output[:,:,:self.hidden_size]+output[:,:,self.hidden_size:]\n",
        "    return output,hidden"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn.utils import weight_norm\n",
        "\n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        self.conv2.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "\n",
        "class TemporalConvNet(nn.Module):\n",
        "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
        "        super(TemporalConvNet, self).__init__()\n",
        "        layers = []\n",
        "        num_levels = num_channels\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = num_inputs if i == 0 else num_inputs*2\n",
        "            out_channels = num_inputs*2\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
        "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ],
      "metadata": {
        "id": "yG-OhLy-JgCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwsvaRJf0W7h"
      },
      "outputs": [],
      "source": [
        "class EncoderTCN(nn.Module):\n",
        "    def __init__(self, hidden_size,embedding, n_layers, kernel_size=3, dropout=0.2):\n",
        "        super(EncoderTCN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "        self.tcn = TemporalConvNet(hidden_size,n_layers,kernel_size, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size*2, hidden_size)\n",
        "\n",
        "    def forward(self, input_seq, input_length):\n",
        "        embedded = self.embedding(input_seq)\n",
        "        output = self.tcn(embedded.permute(0,2,1))\n",
        "        output = output.permute(0,2,1)\n",
        "        output=self.fc(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqZXHN7Y0tnu"
      },
      "source": [
        "###2.Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42rYOxhi0xwM"
      },
      "outputs": [],
      "source": [
        "# Luong attention layer\n",
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "        if self.method not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "        self.hidden_size = hidden_size\n",
        "        if self.method == 'general':\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def concat_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "        return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # Calculate the attention weights (energies) based on the given method\n",
        "        if self.method == 'general':\n",
        "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'dot':\n",
        "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "        # Transpose max_length and batch_size dimensions\n",
        "        attn_energies = attn_energies.t()\n",
        "\n",
        "        # Return the softmax normalized probability scores (with added dimension)\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd3tNSuo48mw"
      },
      "outputs": [],
      "source": [
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        # Note: we run this one step (word) at a time\n",
        "        # Get embedding of current input word\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "        # Forward through unidirectional GRU\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        # Calculate attention weights from the current GRU output\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        # attn_weights_tcn=self.attn(rnn_output, encoderTCN_outputs)\n",
        "        # attn_weights=(0.7*(attn_weights_rnn))+(0.3*(attn_weights_tcn))\n",
        "        # attn_weights=torch.cat((attn_weights_rnn,attn_weights_tcn),dim=1)\n",
        "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        # context=context.view(-1, context.shape[-1]*2)\n",
        "        # print('context:',context.shape)\n",
        "        # print('rnn_output: ',rnn_output.shape)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        # Predict next word using Luong eq. 6\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        # Return output and final hidden state\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRNW5rb0YQfJ"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uH3U1KQdYSNQ"
      },
      "outputs": [],
      "source": [
        "def maskNLLLoss(decoder_out,target,mask):\n",
        "  nTotal=mask.sum()\n",
        "  target=target.view(-1,1)\n",
        "  gathered_tensor=torch.gather(decoder_out,1,target)\n",
        "  crossEntropy= -torch.log(gathered_tensor)\n",
        "  loss=crossEntropy.masked_select(mask)\n",
        "  loss=loss.mean()\n",
        "  loss=loss.to(device)\n",
        "  return loss,nTotal.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJLcYn14Z1hK"
      },
      "outputs": [],
      "source": [
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoderRNN, decoder, embedding,\n",
        "          encoderRNN_optimizer, decoder_optimizer, batch_size, clip,encoderTCN,encoderTCN_optimizer,beta):\n",
        "\n",
        "    encoderRNN.train()\n",
        "    encoderTCN.train()\n",
        "    decoder.train()\n",
        "    # Zero gradients\n",
        "    encoderRNN_optimizer.zero_grad()\n",
        "    encoderTCN_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Set device options\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "    # Lengths for rnn packing should always be on the cpu\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "\n",
        "    # Initialize variables\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # Forward pass through encoder\n",
        "    encoderRNN_outputs, encoder_hidden = encoderRNN(input_variable, lengths)\n",
        "  \n",
        "    encoderTCN_outputs=encoderTCN(input_variable, lengths)\n",
        "   \n",
        "    encoder_outputs=((beta)*encoderRNN_outputs)+((1-beta)*encoderTCN_outputs)\n",
        "\n",
        "  \n",
        "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "    decoder_input = torch.LongTensor([[SOS_tok for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Set initial decoder hidden state to the encoder's final hidden state\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    # Determine if we are using teacher forcing this iteration\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "    # use_teacher_forcing = False\n",
        "    # Forward batch of sequences through decoder one time step at a time\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # Teacher forcing: next input is current target\n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # No teacher forcing: next input is decoder's own current output\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    # Perform backpropatation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients: gradients are modified in place\n",
        "    _ = nn.utils.clip_grad_norm_(encoderRNN.parameters(), clip)\n",
        "    _ = nn.utils.clip_grad_norm_(encoderTCN.parameters(), clip)\n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    # Adjust model weights\n",
        "    encoderRNN_optimizer.step()\n",
        "    encoderTCN_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return sum(print_losses) / n_totals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYFjoo392jGG"
      },
      "outputs": [],
      "source": [
        "def evaluateInput(input_variable, lengths, target_variable, mask, max_target_len, encoderRNN, decoder, \n",
        "                  embedding,encoderRNN_optimizer, decoder_optimizer, batch_size, clip,encoderTCN,encoderTCN_optimizer,beta):\n",
        "\n",
        "  with torch.no_grad():\n",
        "    encoderRNN.eval()\n",
        "    encoderTCN.eval()\n",
        "    decoder.eval()\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "      # Lengths for rnn packing should always be on the cpu\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "\n",
        "      # Initialize variables\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    encoderRNN_outputs, encoder_hidden = encoderRNN(input_variable, lengths)\n",
        "    encoderTCN_outputs=encoderTCN(input_variable, lengths)\n",
        "    encoder_outputs=((beta)*encoderRNN_outputs)+((1-beta)*encoderTCN_outputs)\n",
        "\n",
        "      # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "    decoder_input = torch.LongTensor([[SOS_tok for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    for t in range(max_target_len):\n",
        "      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      _, topi = decoder_output.topk(1)\n",
        "      decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "      decoder_input = decoder_input.to(device)\n",
        "      # Calculate and accumulate loss\n",
        "      mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "      loss += mask_loss\n",
        "      print_losses.append(mask_loss.item() * nTotal)\n",
        "      n_totals += nTotal\n",
        "\n",
        "  return sum(print_losses) / n_totals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o8c-c2Vgm9K"
      },
      "outputs": [],
      "source": [
        "def trainIters(model_name, voc, pairs_train,pairs_val, encoderRNN, decoder, encoderRNN_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, \n",
        "               save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename,encoderTCN,encoderTCN_optimizer,epoch,beta):\n",
        "    num_batch=len(pairs_train)//batch_size + int(len(pairs_train)% batch_size != 0)\n",
        "    n_iteration=epoch*num_batch\n",
        "    # Load batches for each iteration\n",
        "    training_batches = [batch2TrainData(voc, [random.choice(pairs_train) for _ in range(batch_size)])\n",
        "                      for _ in range(n_iteration)]\n",
        "    validation_batches=[batch2TrainData(voc, [random.choice(pairs_val) for _ in range(batch_size)])\n",
        "                      for _ in range(n_iteration)]\n",
        "    \n",
        "    training_loss=[]\n",
        "    validation_loss=[]\n",
        "    # Initializations\n",
        "    print('Initializing ...')\n",
        "    start_iteration = 1\n",
        "    print_train_loss = 0\n",
        "    print_val_loss = 0\n",
        "    epoch=1\n",
        "    if loadFilename:\n",
        "        start_iteration = checkpoint['iteration'] + 1\n",
        "\n",
        "    # Training loop\n",
        "    print(\"Training...\")\n",
        "    for iteration in range(start_iteration, n_iteration + 1):\n",
        "        training_batch = training_batches[iteration - 1]\n",
        "        validation_batch = validation_batches[iteration - 1]\n",
        "        # Extract fields from batch\n",
        "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "        # Run a training iteration with batch\n",
        "        train_loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoderRNN,\n",
        "                     decoder, embedding, encoderRNN_optimizer, decoder_optimizer, batch_size, clip,encoderTCN,encoderTCN_optimizer,beta)\n",
        "        \n",
        "        input_variable, lengths, target_variable, mask, max_target_len = validation_batch\n",
        "        val_loss = evaluateInput(input_variable, lengths, target_variable, mask, max_target_len, encoderRNN,\n",
        "                     decoder, embedding, encoderRNN_optimizer, decoder_optimizer, batch_size, clip,encoderTCN,encoderTCN_optimizer,beta)\n",
        "        print_train_loss += train_loss\n",
        "        print_val_loss+= val_loss\n",
        "        # Print progress\n",
        "        if iteration % num_batch == 0:\n",
        "            print_loss_avg_train = print_train_loss / num_batch\n",
        "            print_loss_avg_val = print_val_loss / num_batch\n",
        "            training_loss.append(print_loss_avg_train)\n",
        "            validation_loss.append(print_loss_avg_val)\n",
        "            print(\"Epoch: {}; Percent complete: {:.1f}%; Average train loss: {:.4f}   Average val loss: {:.4f}\".format(epoch, iteration / n_iteration * 100, print_loss_avg_train,print_loss_avg_val))\n",
        "            print_train_loss = 0\n",
        "            print_val_loss= 0\n",
        "            epoch+=1\n",
        "        if epoch==5:\n",
        "          embedding.requires_grad=True\n",
        "    \n",
        "    return training_loss,validation_loss     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGdXMDuUiFxg"
      },
      "source": [
        "###Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fnp-rcUZiIku",
        "outputId": "0a864819-803b-458e-9fa3-31668d44d53a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n"
          ]
        }
      ],
      "source": [
        "# Configure models\n",
        "model_name = 'cb_model_rnn_attention'\n",
        "attn_model = 'dot'\n",
        "#attn_model = 'general'\n",
        "#attn_model = 'concat'\n",
        "hidden_size = 300\n",
        "encoder_n_layers = 4\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.2\n",
        "batch_size = 64\n",
        "\n",
        "# Set checkpoint to load from; set to None if starting from scratch\n",
        "loadFilename = None\n",
        "# checkpoint_iter = 10000\n",
        "# loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
        "\n",
        "\n",
        "# Load model if a loadFilename is provided\n",
        "if loadFilename:\n",
        "    # If loading on same machine the model was trained on\n",
        "    checkpoint = torch.load(loadFilename)\n",
        "    # If loading a model trained on GPU to CPU\n",
        "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
        "    encoder_sd = checkpoint['en']\n",
        "    decoder_sd = checkpoint['de']\n",
        "    encoder_optimizer_sd = checkpoint['en_opt']\n",
        "    decoder_optimizer_sd = checkpoint['de_opt']\n",
        "    embedding_sd = checkpoint['embedding']\n",
        "    vocab.__dict__ = checkpoint['voc_dict']\n",
        "\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "# embedding = nn.Embedding(vocab.num_words, hidden_size)\n",
        "# if loadFilename:\n",
        "#     embedding.load_state_dict(embedding_sd)\n",
        "# Initialize encoder & decoder models\n",
        "encoderRNN = EncoderRNN(hidden_size, embedding_layer, encoder_n_layers, dropout)\n",
        "encoderTCN = EncoderTCN(hidden_size, embedding_layer, n_layers=encoder_n_layers)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding_layer, hidden_size, vocab.num_words, decoder_n_layers, dropout)\n",
        "if loadFilename:\n",
        "    encoderRNN.load_state_dict(encoder_sd)\n",
        "    decoder.load_state_dict(decoder_sd)\n",
        "# Use appropriate device\n",
        "encoderRNN = encoderRNN.to(device)\n",
        "encoderTCN=encoderTCN.to(device)\n",
        "decoder = decoder.to(device)\n",
        "print('Models built and ready to go!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bk78jeAg0ie"
      },
      "outputs": [],
      "source": [
        "# Configure training/optimization\n",
        "clip = 50\n",
        "teacher_forcing_ratio = 1.0\n",
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "n_iteration = 0\n",
        "print_every = 1\n",
        "save_every = 500\n",
        "epoch=40\n",
        "\n",
        "# Ensure dropout layers are in train mode\n",
        "encoderRNN.train()\n",
        "encoderTCN.train()\n",
        "decoder.train()\n",
        "\n",
        "# Initialize optimizers\n",
        "print('Building optimizers ...')\n",
        "encoderRNN_optimizer = optim.Adam(encoderRNN.parameters(), lr=learning_rate)\n",
        "encoderTCN_optimizer = optim.Adam(encoderTCN.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "# encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate,momentum=0.9)\n",
        "# decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate * decoder_learning_ratio,momentum=0.09)\n",
        "# if loadFilename:\n",
        "#     encoderRNN_optimizer.load_state_dict(encoder_optimizer_sd)\n",
        "#     decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
        "\n",
        "# # If you have cuda, configure cuda to call\n",
        "# for state in encoder_optimizer.state.values():\n",
        "#     for k, v in state.items():\n",
        "#         if isinstance(v, torch.Tensor):\n",
        "#             state[k] = v.cuda()\n",
        "\n",
        "# for state in decoder_optimizer.state.values():\n",
        "#     for k, v in state.items():\n",
        "#         if isinstance(v, torch.Tensor):\n",
        "#             state[k] = v.cuda()\n",
        "\n",
        "# Run training iterations\n",
        "print(\"Starting Training!\")\n",
        "train_loss,val_loss=trainIters(model_name, vocab, pairs_train,pairs_val, encoderRNN, decoder, encoderRNN_optimizer, decoder_optimizer,\n",
        "           embedding_layer, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "           print_every, save_every, clip, corpus_name, loadFilename,encoderTCN,encoderTCN_optimizer,epoch,beta=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BueZoCWbg7nP"
      },
      "source": [
        "##Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqnm3sVog80f"
      },
      "outputs": [],
      "source": [
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder,encoderTCN, decoder,beta):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.encoderTCN=encoderTCN\n",
        "        self.decoder = decoder\n",
        "        self.beta=beta\n",
        "\n",
        "    def forward(self, input_seq, input_length, max_length):\n",
        "        # Forward input through encoder model\n",
        "        encoderRNN_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
        "        encoderTCN_outputs=encoderTCN(input_seq, input_length)\n",
        "        encoder_outputs=((self.beta)*encoderRNN_outputs)+((1-self.beta)*encoderTCN_outputs)\n",
        "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "        # Initialize decoder input with SOS_token\n",
        "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_tok\n",
        "        # Initialize tensors to append decoded words to\n",
        "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
        "        all_scores = torch.zeros([0], device=device)\n",
        "        # Iteratively decode one word token at a time\n",
        "        for _ in range(max_length):\n",
        "            # Forward pass through decoder\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # Obtain most likely word token and its softmax score\n",
        "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "            # Record token and score\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "            # Prepare current token to be next decoder input (add a dimension)\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "        # Return collections of word tokens and scores\n",
        "        return all_tokens, all_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTkI-3HihJwu"
      },
      "outputs": [],
      "source": [
        "def evaluate(searcher, voc, sentence, max_length=MAX_LENGTH):\n",
        "    ### Format input sentence as a batch\n",
        "    # words -> indexes\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
        "    # Create lengths tensor\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    # Transpose dimensions of batch to match models' expectations\n",
        "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
        "    # Use appropriate device\n",
        "    input_batch = input_batch.to(device)\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "    # Decode sentence with searcher\n",
        "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "    # indexes -> words\n",
        "    decoded_words = [voc.idx2word[token.item()] for token in tokens]\n",
        "    return decoded_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjbTvaboxQsH"
      },
      "source": [
        "##Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjmJLN7Mg9pP"
      },
      "outputs": [],
      "source": [
        "def evalInput(searcher, voc):\n",
        "    input_sentence = ''\n",
        "    while(1):\n",
        "        try:\n",
        "            # Get input sentence\n",
        "            input_sentence = input('> ')\n",
        "            # Check if it is quit case\n",
        "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
        "            # Normalize sentence\n",
        "            input_sentence = normalizeString(input_sentence)\n",
        "            # Evaluate sentence\n",
        "            output_words = evaluate( searcher, voc, input_sentence)\n",
        "            # Format and print response sentence\n",
        "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "            print('Bot:', ' '.join(output_words))\n",
        "\n",
        "        except KeyError:\n",
        "            print(\"Error: Encountered unknown word.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOMRkWKmhN3w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "03d1dd6f-e6e3-4f89-ed45-5514e6e4dd6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> नमस्कार कैसे हो तुम?\n",
            "Bot: धन्यवाद।\n",
            "> चलो कहीं बाहर खाने चलते हैं\n",
            "Bot: ठीक है।\n",
            "> मैं आज बहुत खुश हूं\n",
            "Bot: क्या आप जानते हैं कि आपको किस तरह का कमरा चाहिए\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-22757e538745>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Begin chatting (uncomment and run the following line to begin)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mevalInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-4b5c7b694a75>\u001b[0m in \u001b[0;36mevalInput\u001b[0;34m(searcher, voc)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;31m# Get input sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0minput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'> '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0;31m# Check if it is quit case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'q'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# Set dropout layers to eval mode\n",
        "encoderTCN.eval()\n",
        "decoder.eval()\n",
        "encoderRNN.eval()\n",
        "\n",
        "# Initialize search module\n",
        "searcher = GreedySearchDecoder(encoderRNN,encoderTCN, decoder,beta=1)\n",
        "# searcher = BeamSearchDecoder(encoderRNN,encoderTCN, decoder,0.7,3)\n",
        "\n",
        "# Begin chatting (uncomment and run the following line to begin)\n",
        "evalInput(searcher, vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ref6QCzhSCl"
      },
      "source": [
        "###Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jzs3IQqh0oF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc391d28-bce5-48fe-b584-74a0e70ab1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rztVjmXMhyzi"
      },
      "outputs": [],
      "source": [
        "from rouge import Rouge \n",
        "def calculateRogue(test_data):\n",
        "  prediction=[]\n",
        "  actual=[]\n",
        "  for pair in test_data:\n",
        "    pred = evaluate(searcher, vocab, pair[0])\n",
        "    pred[:] = [x for x in pred if not (x == 'EOS' or x == 'PAD')]\n",
        "    pred=' '.join(pred)\n",
        "    if len(pred)<=0:\n",
        "      continue\n",
        "    prediction.append(pred)\n",
        "    actual.append(pair[1])\n",
        "  rouge = Rouge()\n",
        "  scores = rouge.get_scores(prediction, actual,avg=True)\n",
        "  print(scores)\n",
        "  return prediction,actual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_c0lP-EWpJh"
      },
      "outputs": [],
      "source": [
        "##Bleu Score\n",
        "def bleu_score(guess, answer):\n",
        "    \"\"\"Compute approximate BLEU score between guess and a set of answers.\"\"\"\n",
        "    bleu1=sentence_bleu([normalizeString(answer).split()],normalizeString(guess).split(\" \"),weights=[1,0,0,0])\n",
        "    bleu2=sentence_bleu([normalizeString(answer).split()],normalizeString(guess).split(\" \"),weights=[0.5,0.5,0,0])\n",
        "    bleu3=sentence_bleu([normalizeString(answer).split()],normalizeString(guess).split(\" \"),weights=[0.3,0.3,0.3,0])\n",
        "    return [bleu1,bleu2,bleu3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWcmPy56_A_G"
      },
      "outputs": [],
      "source": [
        "##f1_score\n",
        "def prec_recall_f1_score(pred_items, gold_items)->float:\n",
        "    common = Counter(gold_items) & Counter(pred_items)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(pred_items)\n",
        "    recall = 1.0 * num_same / len(gold_items)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def f1_score(guess, answer)-> float:\n",
        "    \"\"\"Return the max F1 score between the guess and *any* answer.\"\"\"\n",
        "    if guess is None or answer is None:\n",
        "        return 0\n",
        "    g_tokens = normalizeString(guess).split()\n",
        "    a_token=normalizeString(answer).split()\n",
        "    return prec_recall_f1_score(g_tokens,a_token )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTDySMdEBmzx"
      },
      "outputs": [],
      "source": [
        "##Meteor Score\n",
        "def _meteor_score(guess,answer):\n",
        "  return meteor_score([normalizeString(answer).split()],normalizeString(guess).split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnJLI8k-Xw5l"
      },
      "outputs": [],
      "source": [
        "def evaluateMetrics(test_data):\n",
        "  num_samples=len(test_data)\n",
        "  f1=0.0\n",
        "  bleu=[0.0,0.0,0.0]\n",
        "  meteor=0.0\n",
        "  for pair in test_data:\n",
        "    pred = evaluate(searcher, vocab, pair[0])\n",
        "    pred[:] = [x for x in pred if not (x == 'EOS' or x == 'PAD')]\n",
        "    pred=' '.join(pred)\n",
        "    actual=pair[1]\n",
        "    f1+=f1_score(pred,actual)\n",
        "    bleu=[a+b for a,b in zip(bleu,bleu_score(pred,actual))]\n",
        "    meteor+=_meteor_score(pred,actual)\n",
        "  f1=(f1/num_samples)*100\n",
        "  bleu[:]=[(x/num_samples)*100 for x in bleu]\n",
        "  meteor=(meteor/num_samples)*100\n",
        "  print(f'F1_score: {f1:.2f}')\n",
        "  print(f'BLEU-1_score: {bleu[0]:.3f}')\n",
        "  print(f'BLEU-2_score: {bleu[1]:.3f}')\n",
        "  print(f'BLEU-3_score: {bleu[2]:.2f}')\n",
        "  print(f'meteor_score: {meteor:.2f}')\n",
        "  return f1,bleu,meteor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l46UlgapF1tX"
      },
      "outputs": [],
      "source": [
        "print('Reading lines from formatted test files please wait...')\n",
        "test_lines=open(test_file,encoding='utf-8').read().strip().split('\\n')\n",
        "pairs_test_data=[[normalizeString(s) for s in pair.split('\\t')] for pair in test_lines]\n",
        "print('Done Reading..... total train length {}'.format(len(pairs_test_data)))\n",
        "pairs_test_data=filterPairs(pairs_test_data)\n",
        "print('After filtering, there are {} pair'.format(len(pairs_test_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PMyByHc3lVN"
      },
      "outputs": [],
      "source": [
        "f1,bleu,meteor=evaluateMetrics(pairs_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_r1ZVDCmGNP"
      },
      "outputs": [],
      "source": [
        "pred,actual=calculateRogue(pairs_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvxaGc2gpWsd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}